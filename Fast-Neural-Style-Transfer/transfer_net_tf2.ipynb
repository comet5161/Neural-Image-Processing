{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "img_size = 256\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.build the transfer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MEAN_VALUES = np.array([123.68, 116.779, 103.939]).reshape((1, 1, 1, 3)) # 通道颜色均值\n",
    "#k_initializer = tf.truncated_normal_initializer(0, 0.1)\n",
    "k_initializer = keras.initializers.TruncatedNormal(0, 0.1)\n",
    "variation_weight = 0.01\n",
    "kernel_regularizer =  keras.regularizers.l2(variation_weight)\n",
    "bias_regularizer = keras.regularizers.l2(variation_weight) \n",
    "def relu(X):\n",
    "    return keras.layers.Activation('relu')(X)\n",
    "\n",
    "def instance_norm(X):\n",
    "    return keras.layers.LayerNormalization()(X)\n",
    "\n",
    "def conv2d(inputs, filters, kernel_size, strides, name = \"noname\"):\n",
    "    return keras.layers.Conv2D(filters, kernel_size, strides, padding=\"same\", kernel_initializer=k_initializer, kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer, name = name)(inputs)\n",
    "\n",
    "def deconv2d(inputs, filters, kernel_size = 3, strides = 1, name=\"noname\"):\n",
    "    return tf.keras.layers.Conv2DTranspose(filters, kernel_size, strides,  padding=\"same\", kernel_initializer=k_initializer, kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer, name=name)(inputs)\n",
    "\n",
    "    # 残差网络\n",
    "def residual(inputs, filters = 128, kernel_size = 3, name=\"noname\"):\n",
    "    X = relu(conv2d(inputs, filters, kernel_size, 1, name=name+\"_1\"))\n",
    "    X = conv2d(X, filters, kernel_size, 1, name=name+\"_2\")\n",
    "    return keras.layers.Add()([inputs, X])\n",
    "\n",
    "def get_transfer_model(input_shape=(256, 256, 3), name=\"style_transfer_net\"):\n",
    "    img_inputs = keras.Input(input_shape, name=\"transfer_inputs\")\n",
    "    #X = tf.pad(img_inputs - MEAN_VALUES, [[0, 0], [10, 10], [10, 10], [0, 0]], mode='reflect')\n",
    "    X = keras.layers.Subtract()([img_inputs, MEAN_VALUES])\n",
    "    X = relu(instance_norm(conv2d(X, 32, 9, 1, name=\"conv1\")))\n",
    "    X = relu(instance_norm(conv2d(X, 64, 3, 2, name=\"conv2\")))\n",
    "    X = relu(instance_norm(conv2d(X, 128, 3, 2, name=\"conv3\")))\n",
    "\n",
    "    for i in range(5):\n",
    "        X = residual(X, 128, 3, name=\"res\"+str(i))\n",
    "\n",
    "    X = relu(instance_norm(deconv2d(X, 64, 3, 2, name=\"conv4\")))\n",
    "    X = relu(instance_norm(deconv2d(X, 32, 3, 2, name=\"conv5\")))\n",
    "    X = keras.layers.Activation('tanh')(instance_norm(conv2d(X, 3, 9, 1, name=\"conv6\")))\n",
    "    #X = tf.nn.tanh(instance_norm(conv2d(X, 3, 9, 1, name=\"conv6\")))\n",
    "    #X = (X + 1) * (255.0/2)\n",
    "    X = keras.layers.Lambda(lambda x: (x+1)*(255.0/2), name=\"transfer_outputs\")(X)\n",
    "    return keras.Model(inputs=img_inputs, outputs=X, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test transfer model\n",
    "# test_module = transfer_model()\n",
    "# test_module.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(test_model , show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##  import VGG19\n",
    "### Content feature and Content loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG19(weights='imagenet', include_top=False)\n",
    "# set vgg19 to untrainable\n",
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get extract model\n",
    "OUTPUT_LAYERS=[\"output_feature_\" + str(i) for i in range(4)]\n",
    "STYLE_LAYERS = ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3']\n",
    "def get_feature_extract_model(vgg19):\n",
    "    features_list  = [vgg19.get_layer(layer_name).output for layer_name in STYLE_LAYERS]\n",
    "    return keras.Model(inputs=vgg19.input, outputs=features_list, name='output_feature')\n",
    "\n",
    "def get_features(img_path, model):\n",
    "    img = image.load_img(img_path, target_size=(img_size, img_size))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return model(x)\n",
    "\n",
    "feat_extract_model = get_feature_extract_model(vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get style and content image features\n",
    "img_input = keras.Input(shape=(img_size, img_size, 3), name=\"img\")\n",
    "\n",
    "# content_features = feat_extract_model(img_input)\n",
    "content_features = get_features('content/0.jpg', feat_extract_model)\n",
    "style_img_path='styles/wave.jpg'\n",
    "style_features = get_features(style_img_path, feat_extract_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tensor in style_features:\n",
    "#     print(tensor.shape)\n",
    "print(content_features)\n",
    "print(style_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get generate features\n",
    "\n",
    "transfer_model = get_transfer_model()\n",
    "X = transfer_model(img_input)\n",
    "generate_features = feat_extract_model(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content loss\n",
    "def get_content_loss(content_feature, generate_feature):\n",
    "    content_loss = 2 * tf.nn.l2_loss(content_feature-generate_feature) / tf.cast(tf.size(content_feature), dtype=tf.float32)\n",
    "    return content_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style loss\n",
    "\n",
    "def get_style_gram(style_features): # input: list of tensor\n",
    "    grams = []\n",
    "    for feat in style_features:\n",
    "        feat = np.reshape(feat, (-1, feat.shape[3]))\n",
    "        gram = np.matmul(feat.T, feat) / feat.size\n",
    "        grams.append(gram)\n",
    "    return grams\n",
    "\n",
    "style_grams = get_style_gram(style_features)\n",
    "\n",
    "def get_style_loss(style_gram, generate_feature):\n",
    "    layer = generate_feature\n",
    "    shape = layer.get_shape().as_list()\n",
    "    bs, height, width, channel = shape[0], shape[1], shape[2], shape[3]\n",
    "    features = tf.reshape(layer, (-1, height * width, channel))\n",
    "    gram = tf.matmul(tf.transpose(features, (0,2,1)), features) / (height * width * channel*1.0)\n",
    "    size = tf.cast(tf.size(layer), tf.float32)\n",
    "    style_loss = 2 * tf.nn.l2_loss(gram - style_gram) / size\n",
    "    #style_loss = tf.reduce_sum(style_loss, name = 'style_loss')\n",
    "    return style_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# feat_extract_model.summary()\n",
    "# keras.utils.plot_model(feat_extract_model , show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train model\n",
    "\n",
    "train_model = keras.Model(inputs=img_input, outputs=generate_features, name='train_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model.summary()\n",
    "# keras.utils.plot_model(train_model , show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = get_features(\"content/0.jpg\",train_model)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in train_model.trainable_weights:\n",
    "#     print(x.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "\n",
    "content_weight = 1\n",
    "style_weight = 250\n",
    "def loss_fn_0(y_true, y_pred):\n",
    "    style_loss = get_style_loss(style_grams[0], y_pred) * style_weight\n",
    "    return style_loss\n",
    "def loss_fn_1(y_true, y_pred):\n",
    "    style_loss = get_style_loss(style_grams[1], y_pred) * style_weight\n",
    "    return style_loss\n",
    "def loss_fn_2(y_true, y_pred):\n",
    "    con = feat_extract_model.predict_on_batch(y_true)\n",
    "    # con = feat_extract_model.predict(y_true)\n",
    "    content_loss = get_content_loss(content_features[2], y_pred)\n",
    "    style_loss = get_style_loss(style_grams[2], y_pred)\n",
    "    total_loss = content_weight*content_loss + style_weight*style_loss\n",
    "    return total_loss\n",
    "def loss_fn_3(y_true, y_pred):\n",
    "    style_loss = get_style_loss(style_grams[3], y_pred) * style_weight\n",
    "    return style_loss\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_fn = [loss_fn_0, loss_fn_1, loss_fn_2, loss_fn_3]\n",
    "train_model.compile(optimizer=opt, loss=loss_fn, loss_weights=[1, 1, 1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ## 加载图片\n",
    "    X_data = np.load('train/train2014_5000.preprocessing.npy')\n",
    "    X_data = X_data[0:60, :, :, :]\n",
    "    Y_data = X_data.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin training\n",
    "STYLE_LAYERS =  ['output_feature', 'output_feature_1', 'output_feature_2', 'output_feature_3']\n",
    "\n",
    "# Y_data = np.zeros([4, X_data.shape[0] ])\n",
    "\n",
    "# outs = {STYLE_LAYERS[i]: Y_data[i] for i in range(4)}\n",
    "outs = {STYLE_LAYERS[i]: Y_data for i in range(4)}\n",
    "\n",
    "train_model.fit(\n",
    "    {'img':X_data},\n",
    "    outs,\n",
    "    batch_size=1,\n",
    "    epochs=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_img_path= 'content/0.jpg'\n",
    "sample_size = 256\n",
    "# , target_size=(sample_size, sample_size)\n",
    "img = image.load_img(sample_img_path , target_size=(sample_size, sample_size))\n",
    "x = image.img_to_array(img)\n",
    "plt.imshow(x.astype(int))\n",
    "# print(x.shape)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "predit_model = train_model.get_layer(\"style_transfer_net\")\n",
    "\n",
    "#imsave('content/0_wave.jpg', result[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predit_model(x)\n",
    "result = tf.cast(result, dtype=tf.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.axis('off')\n",
    "plt.imshow(result[0])\n",
    "# print(x[0].shape)\n",
    "# print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = feat_extract_model.predict(x)\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tf2-gpu': conda)",
   "language": "python",
   "name": "python37764bittf2gpucondace5cdca58a4447c2a3d83a62d4d83778"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}