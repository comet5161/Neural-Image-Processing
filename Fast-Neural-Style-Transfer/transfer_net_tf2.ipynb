{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "transfer_net_tf2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nceUOL87L8VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %tensorflow_version 2.1.x\n",
        "# import tensorflow as tf\n",
        "# print(tf.__version__)\n",
        "\n",
        "style_img_path='styles/wave.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7og6zQxshJ0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbiNwI92grHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# coding: utf-8\n",
        "import tensorflow as tf # require tensorflow v2\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.client import device_lib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "img_size = 256\n",
        "\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7A-iT8vrz4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
        "\n",
        "for gpu in gpus:\n",
        "    print(gpu)\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE-NwQR_iNJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKpi1d0vhdYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # !mkdir /root/.ssh\n",
        "# !cp -r \"drive/My Drive/.ssh\" /root/\n",
        "# !chmod 600 /root/.ssh/id_rsa\n",
        "# !chmod 644 /root/.ssh/id_rsa.pub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nxjfCPWhi86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "# os.chdir('/content/Neural-Image-Processing/Fast-Neural-Style-Transfer')\n",
        "os.chdir('/content/drive/My Drive/github/Neural-Image-Processing/Fast-Neural-Style-Transfer') #\n",
        "# os.chdir('/home/xing/文档/Git_Repository/Neural-Image-Processing/Fast-Neural-Style-Transfer/')\n",
        "#print(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0ijoaUdhuBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoMA91wEgrHy",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## 2.build the transfer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3i3oxdWgrHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "MEAN_VALUES = np.array([123.68, 116.779, 103.939]).reshape((1, 1, 1, 3)) # 通道颜色均值\n",
        "#k_initializer = tf.truncated_normal_initializer(0, 0.1)\n",
        "k_initializer = keras.initializers.TruncatedNormal(0, 0.1)\n",
        "variation_weight = 0.01\n",
        "kernel_regularizer =  keras.regularizers.l2(variation_weight)\n",
        "bias_regularizer = keras.regularizers.l2(variation_weight) \n",
        "activity_regularizer = keras.regularizers.l2(0.01)\n",
        "def relu(X):\n",
        "    return keras.layers.Activation('relu')(X)\n",
        "\n",
        "def instance_norm(X):\n",
        "    # return keras.layers.BatchNormalization()(X)\n",
        "    return tfa.layers.InstanceNormalization(#axis=3, \n",
        "                                    center=True, \n",
        "                                    scale=True,\n",
        "                                    beta_initializer=\"random_uniform\",\n",
        "                                    gamma_initializer=\"random_uniform\") (X)\n",
        "    #return keras.layers.LayerNormalization()(X)\n",
        "# kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer ,\n",
        "# kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer,  \n",
        "def conv2d(inputs, filters, kernel_size, strides, name = \"noname\"):\n",
        "    return keras.layers.Conv2D(filters, kernel_size, strides, padding=\"same\", kernel_initializer=k_initializer, name = name)(inputs)\n",
        "\n",
        "def deconv2d(inputs, filters, kernel_size = 3, strides = 1, name=\"noname\"):\n",
        "    #return tf.keras.layers.Conv2DTranspose(filters, kernel_size, strides,  padding=\"same\", kernel_initializer=k_initializer, activity_regularizer=activity_regularizer, name=name)(inputs)\n",
        "    # shape = tf.shape(inputs)\n",
        "    shape = inputs.get_shape().as_list()\n",
        "    \n",
        "    height, width = shape[1], shape[2]\n",
        "    # 近邻插值法，\n",
        "    print(inputs)\n",
        "    h0 = tf.image.resize(inputs, [height * strides * 2, width * strides * 2], tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    \n",
        "    return conv2d(h0, filters, kernel_size, strides, name)\n",
        "\n",
        "    # 残差网络\n",
        "def residual(inputs, filters = 128, kernel_size = 3, name=\"noname\"):\n",
        "    X = relu(conv2d(inputs, filters, kernel_size, 1, name=name+\"_1\"))\n",
        "    X = conv2d(X, filters, kernel_size, 1, name=name+\"_2\")\n",
        "    return keras.layers.Add()([inputs, X])\n",
        "\n",
        "def get_transfer_model(input_shape=(256, 256, 3), name=\"style_transfer_net\"):\n",
        "    img_inputs = keras.Input(input_shape, name=\"inputs\")\n",
        "    #X = tf.pad(img_inputs - MEAN_VALUES, [[0, 0], [10, 10], [10, 10], [0, 0]], mode='reflect')\n",
        "    X = keras.layers.Subtract()([img_inputs, MEAN_VALUES])\n",
        "    X = relu(instance_norm(conv2d(X, 32, 9, 1, name=\"conv1\")))\n",
        "    X = relu(instance_norm(conv2d(X, 64, 3, 2, name=\"conv2\")))\n",
        "    X = relu(instance_norm(conv2d(X, 128, 3, 2, name=\"conv3\")))\n",
        "\n",
        "    for i in range(5):\n",
        "        X = residual(X, 128, 3, name=\"res\"+str(i))\n",
        "\n",
        "    X = relu(instance_norm(deconv2d(X, 64, 3, 2, name=\"conv4\")))\n",
        "    X = relu(instance_norm(deconv2d(X, 32, 3, 2, name=\"conv5\")))\n",
        "    X = keras.layers.Activation('tanh')(instance_norm(conv2d(X, 3, 9, 1, name=\"conv6\")))\n",
        "    #X = tf.nn.tanh(instance_norm(conv2d(X, 3, 9, 1, name=\"conv6\")))\n",
        "    X = (X + 1) * (255.0/2)\n",
        "    #X = keras.layers.Lambda(lambda x: (x+1)*(255.0/2), name=\"transfer_outputs\")(X)\n",
        "    return keras.Model(inputs=img_inputs, outputs=X, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zdYe7gNgrH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # test transfer model\n",
        "# test_module = get_transfer_model()\n",
        "# test_module.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBzs95R9grH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras.utils.plot_model(test_model , show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr_6jLY0grIC",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "##  import VGG19\n",
        "### Content feature and Content loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFue0cU4grIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# content loss\n",
        "def get_content_loss(content_features, generate_features):\n",
        "    content_loss = 2 * tf.nn.l2_loss(content_features[2]-generate_features[2]) / tf.cast(tf.size(content_features[2]), dtype=tf.float32)\n",
        "    return content_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcIo3GJ2grIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# style loss\n",
        "\n",
        "def get_style_gram(style_features): # input: list of tensor\n",
        "    grams = []\n",
        "    for feat in style_features:\n",
        "        feat = np.reshape(feat, (-1, feat.shape[3]))\n",
        "        gram = np.matmul(feat.T, feat) / feat.size\n",
        "        grams.append(gram)\n",
        "    return grams\n",
        "\n",
        "def get_style_loss( generate_features, style_features):\n",
        "    style_grams = get_style_gram(style_features)\n",
        "    for i in range(len(generate_features)):\n",
        "        layer = generate_features[i]\n",
        "        shape = layer.get_shape().as_list()\n",
        "        bs, height, width, channel = shape[0], shape[1], shape[2], shape[3]\n",
        "        features = tf.reshape(layer, (-1, height * width, channel))\n",
        "        gram = tf.matmul(tf.transpose(features, (0,2,1)), features) / (height * width * channel*1.0)\n",
        "        size = tf.cast(tf.size(layer), tf.float32)\n",
        "        style_loss = 2 * tf.nn.l2_loss(gram - style_grams[i]) / size\n",
        "    style_loss = tf.reduce_sum(style_loss, name = 'style_loss')\n",
        "    return style_loss\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX4eypDJgrIl",
        "colab_type": "text"
      },
      "source": [
        "## "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-dZCI5tgrII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get feature extract model\n",
        "OUTPUT_LAYERS=[\"output_feature_\" + str(i) for i in range(4)]\n",
        "STYLE_LAYERS = ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3']\n",
        "def get_feature_extract_model(vgg19):\n",
        "    features_list  = [vgg19.get_layer(layer_name).output for layer_name in STYLE_LAYERS]\n",
        "    return keras.Model(inputs=vgg19.input, outputs=features_list, name='output_feature')\n",
        "\n",
        "def get_features(img_path, model):\n",
        "    img = image.load_img(img_path, target_size=(img_size, img_size))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return model(x)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pkxGtR6grIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# variation loss\n",
        "def get_total_variation_loss(inputs):\n",
        "    h = inputs[:, :-1, :, :] - inputs[:, 1:, :, :]\n",
        "    w = inputs[:, :, 1:, :]\n",
        "    h_size = tf.cast(tf.size(h), tf.float32)\n",
        "    w_size = tf.cast(tf.size(w), tf.float32)\n",
        "    return tf.nn.l2_loss(h)/ h_size + tf.nn.l2_loss(w) / w_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kL8yd2T3XO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tpu\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcM-5zggJ6_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transfer_model.summary()\n",
        "# transfer_model.input.shape\n",
        "# transfer_model.output.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPjfQ4jODhD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss function\n",
        "with tpu_strategy.scope():\n",
        "    # with strategy.scope():\n",
        "    vgg19_1 = VGG19(weights='imagenet', include_top=False)\n",
        "    # set vgg19 to untrainable\n",
        "    for layer in vgg19_1.layers:\n",
        "        layer.trainable = False\n",
        "    feat_extract_model = get_feature_extract_model(vgg19_1)\n",
        "    style_features = get_features(style_img_path, feat_extract_model)\n",
        "    transfer_model = get_transfer_model()\n",
        "\n",
        "    content_weight = 1\n",
        "    style_weight = 250\n",
        "    variation_weight = 0.01\n",
        "\n",
        "    # x = keras.layers.concatenate([transfer_model.input, transfer_model.output], axis=0)\n",
        "    # print(\"666\")\n",
        "    # print(x)\n",
        "    # y = feat_extract_model(x)\n",
        "    # content_features = y[0]\n",
        "    # generate_features = y[1]\n",
        "\n",
        "    content_features = feat_extract_model(transfer_model.input)\n",
        "    generate_features = feat_extract_model(transfer_model.output)\n",
        "    # style_features\n",
        "    content_loss = get_content_loss(content_features, generate_features)\n",
        "    style_loss = get_style_loss(generate_features, style_features)\n",
        "    variation_loss = get_total_variation_loss(transfer_model.output)\n",
        "    total_loss = content_weight*content_loss + style_weight*style_loss + variation_weight*variation_loss\n",
        "\n",
        "    transfer_model.add_loss(total_loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew9b2_aygrIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "batch_size = 1 * tpu_strategy.num_replicas_in_sync\n",
        "print(batch_size)\n",
        "# strategy = tf.distribute.\n",
        "\n",
        "    # with tpu_strategy.scope():\n",
        "# with strategy.scope():\n",
        "\n",
        "def loss_fn(true_val, pred_val):\n",
        "    return tf.reduce_mean(pred_val) + tf.reduce_mean(true_val)\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "    transfer_model.compile(optimizer=opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urRiNTMbgrIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ## 加载图片\n",
        "X_data = np.load('train/train2014_5000.preprocessing.npy')\n",
        "print(X_data.shape)\n",
        "\n",
        "# X_data = X_data[0:2048, :, :, :]\n",
        "X_data = X_data[0:4096, :, :, :]\n",
        "X_data = X_data.astype(np.float32)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVjqwgzKntMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# del Y_data\n",
        "# X_data = X_data.astype(int)\n",
        "# transfer_model.summary()\n",
        "# keras.utils.plot_model(transfer_model , show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXawe43DucYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AUTO = tf.data.experimental.AUTOTUNE\n",
        "# Z = (tf.constant(X_data), tf.constant(X_data))\n",
        "# data_set = tf.data.Dataset.from_tensor_slices(Z).batch(batch_size).prefetch(AUTO)\n",
        "# print(data_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLxyJCXSgrI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # begin training\n",
        "\n",
        "steps_per_epoch=1024 // batch_size\n",
        "# transfer_model.fit(X_data, steps_per_epoch=steps_per_epoch, epochs=1)\n",
        "%time transfer_model.fit(X_data[0:2048, :, :, :], epochs=1)\n",
        "%time transfer_model.fit(X_data[2048:4096, :, :, :], epochs=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVsKDcCXgrI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test\n",
        "\n",
        "sample_img_path= 'content/0.jpg'\n",
        "sample_size = 256\n",
        "# , target_size=(sample_size, sample_size)\n",
        "img = image.load_img(sample_img_path , target_size=(sample_size, sample_size))\n",
        "x = image.img_to_array(img)\n",
        "plt.imshow(x.astype(int))\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri1mxU-QgrI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = transfer_model(x)\n",
        "plt.axis('off')\n",
        "# print(result.numpy()[0].astype(int))\n",
        "plt.imshow(result.numpy()[0].astype(int))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTMla25GgrJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras.models.save_model(\n",
        "#     transfer_model,\n",
        "#     'models/111.h5'\n",
        "# )\n",
        "transfer_model.save('models/222.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN30jTLAgrJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transfer_model_v2 = keras.models.load_model('models/111.tf')\n",
        "md = keras.models.load_model('models/222.h5',  {'loss_fn': loss_fn})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPuiNcr-grJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = md.predict(x)\n",
        "plt.axis('off')\n",
        "plt.imshow(result[0].astype(int))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNxL_q0UJYWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "!python '/content/drive/My Drive/github/fast-neural-style-tensorflow/train.py' -c conf/lu.yml #\n",
        "\n",
        "# python36 train.py -c conf/lu.yml"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}