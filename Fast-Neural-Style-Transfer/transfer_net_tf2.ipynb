{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "img_size = 256\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.build the transfer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MEAN_VALUES = np.array([123.68, 116.779, 103.939]).reshape((1, 1, 1, 3)) # 通道颜色均值\n",
    "#k_initializer = tf.truncated_normal_initializer(0, 0.1)\n",
    "k_initializer = keras.initializers.TruncatedNormal(0, 0.1)\n",
    "variation_weight = 0.01\n",
    "kernel_regularizer =  keras.regularizers.l2(variation_weight)\n",
    "bias_regularizer = keras.regularizers.l2(variation_weight) \n",
    "activity_regularizer = keras.regularizers.l2(0.01)\n",
    "def relu(X):\n",
    "    return keras.layers.Activation('relu')(X)\n",
    "\n",
    "def instance_norm(X):\n",
    "    return tfa.layers.InstanceNormalization(axis=3, \n",
    "                                    center=True, \n",
    "                                    scale=True,\n",
    "                                    beta_initializer=\"random_uniform\",\n",
    "                                    gamma_initializer=\"random_uniform\") (X)\n",
    "    #return keras.layers.LayerNormalization()(X)\n",
    "# kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer ,\n",
    "# kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer,  \n",
    "def conv2d(inputs, filters, kernel_size, strides, name = \"noname\"):\n",
    "    return keras.layers.Conv2D(filters, kernel_size, strides, padding=\"same\", kernel_initializer=k_initializer, name = name)(inputs)\n",
    "\n",
    "def deconv2d(inputs, filters, kernel_size = 3, strides = 1, name=\"noname\"):\n",
    "    #return tf.keras.layers.Conv2DTranspose(filters, kernel_size, strides,  padding=\"same\", kernel_initializer=k_initializer, activity_regularizer=activity_regularizer, name=name)(inputs)\n",
    "    # shape = tf.shape(inputs)\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    \n",
    "    height, width = shape[1], shape[2]\n",
    "    # 近邻插值法，\n",
    "    print(inputs)\n",
    "    h0 = tf.image.resize(inputs, [height * strides * 2, width * strides * 2], tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "    return conv2d(h0, filters, kernel_size, strides, name)\n",
    "\n",
    "    # 残差网络\n",
    "def residual(inputs, filters = 128, kernel_size = 3, name=\"noname\"):\n",
    "    X = relu(conv2d(inputs, filters, kernel_size, 1, name=name+\"_1\"))\n",
    "    X = conv2d(X, filters, kernel_size, 1, name=name+\"_2\")\n",
    "    return keras.layers.Add()([inputs, X])\n",
    "\n",
    "def get_transfer_model(input_shape=(256, 256, 3), name=\"style_transfer_net\"):\n",
    "    img_inputs = keras.Input(input_shape, name=\"transfer_inputs\")\n",
    "    #X = tf.pad(img_inputs - MEAN_VALUES, [[0, 0], [10, 10], [10, 10], [0, 0]], mode='reflect')\n",
    "    X = keras.layers.Subtract()([img_inputs, MEAN_VALUES])\n",
    "    X = relu(instance_norm(conv2d(X, 32, 9, 1, name=\"conv1\")))\n",
    "    X = relu(instance_norm(conv2d(X, 64, 3, 2, name=\"conv2\")))\n",
    "    X = relu(instance_norm(conv2d(X, 128, 3, 2, name=\"conv3\")))\n",
    "\n",
    "    for i in range(5):\n",
    "        X = residual(X, 128, 3, name=\"res\"+str(i))\n",
    "\n",
    "    X = relu(instance_norm(deconv2d(X, 64, 3, 2, name=\"conv4\")))\n",
    "    X = relu(instance_norm(deconv2d(X, 32, 3, 2, name=\"conv5\")))\n",
    "    X = keras.layers.Activation('tanh')(instance_norm(conv2d(X, 3, 9, 1, name=\"conv6\")))\n",
    "    #X = tf.nn.tanh(instance_norm(conv2d(X, 3, 9, 1, name=\"conv6\")))\n",
    "    X = (X + 1) * (255.0/2)\n",
    "    #X = keras.layers.Lambda(lambda x: (x+1)*(255.0/2), name=\"transfer_outputs\")(X)\n",
    "    return keras.Model(inputs=img_inputs, outputs=X, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test transfer model\n",
    "# test_module = get_transfer_model()\n",
    "# test_module.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(test_model , show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##  import VGG19\n",
    "### Content feature and Content loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = VGG19(weights='imagenet', include_top=False)\n",
    "# set vgg19 to untrainable\n",
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature extract model\n",
    "OUTPUT_LAYERS=[\"output_feature_\" + str(i) for i in range(4)]\n",
    "STYLE_LAYERS = ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3']\n",
    "def get_feature_extract_model(vgg19):\n",
    "    features_list  = [vgg19.get_layer(layer_name).output for layer_name in STYLE_LAYERS]\n",
    "    return keras.Model(inputs=vgg19.input, outputs=features_list, name='output_feature')\n",
    "\n",
    "def get_features(img_path, model):\n",
    "    img = image.load_img(img_path, target_size=(img_size, img_size))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return model(x)\n",
    "\n",
    "feat_extract_model = get_feature_extract_model(vgg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get style image features\n",
    "\n",
    "style_img_path='styles/wave.jpg'\n",
    "style_features = get_features(style_img_path, feat_extract_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for tensor in style_features:\n",
    "# #     print(tensor.shape)\n",
    "# print(content_features)\n",
    "# print(style_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get generate features\n",
    "\n",
    "transfer_model = get_transfer_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content loss\n",
    "def get_content_loss(content_features, generate_features):\n",
    "    content_loss = 2 * tf.nn.l2_loss(content_features[2]-generate_features[2]) / tf.cast(tf.size(content_features[2]), dtype=tf.float32)\n",
    "    return content_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style loss\n",
    "\n",
    "def get_style_gram(style_features): # input: list of tensor\n",
    "    grams = []\n",
    "    for feat in style_features:\n",
    "        feat = np.reshape(feat, (-1, feat.shape[3]))\n",
    "        gram = np.matmul(feat.T, feat) / feat.size\n",
    "        grams.append(gram)\n",
    "    return grams\n",
    "\n",
    "style_grams = get_style_gram(style_features)\n",
    "\n",
    "def get_style_loss( generate_features):\n",
    "    for i in range(len(generate_features)):\n",
    "        layer = generate_features[i]\n",
    "        shape = layer.get_shape().as_list()\n",
    "        bs, height, width, channel = shape[0], shape[1], shape[2], shape[3]\n",
    "        features = tf.reshape(layer, (-1, height * width, channel))\n",
    "        gram = tf.matmul(tf.transpose(features, (0,2,1)), features) / (height * width * channel*1.0)\n",
    "        size = tf.cast(tf.size(layer), tf.float32)\n",
    "        style_loss = 2 * tf.nn.l2_loss(gram - style_grams[i]) / size\n",
    "    style_loss = tf.reduce_sum(style_loss, name = 'style_loss')\n",
    "    return style_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variation loss\n",
    "def get_total_variation_loss(inputs):\n",
    "    h = inputs[:, :-1, :, :] - inputs[:, 1:, :, :]\n",
    "    w = inputs[:, :, 1:, :]\n",
    "    h_size = tf.cast(tf.size(h), tf.float32)\n",
    "    w_size = tf.cast(tf.size(w), tf.float32)\n",
    "    return tf.nn.l2_loss(h)/ h_size + tf.nn.l2_loss(w) / w_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# feat_extract_model.summary()\n",
    "# keras.utils.plot_model(feat_extract_model , show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "\n",
    "content_weight = 1\n",
    "style_weight = 250\n",
    "variation_weight = 0.01\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    content_features = feat_extract_model.predict_on_batch(y_true)\n",
    "    generate_features = feat_extract_model.predict_on_batch(y_pred)\n",
    "    # style_features\n",
    "    content_loss = get_content_loss(content_features, generate_features)\n",
    "    style_loss = get_style_loss(generate_features)\n",
    "    variation_loss = get_total_variation_loss(y_pred)\n",
    "    total_loss = content_weight*content_loss + style_weight*style_loss + variation_weight*variation_loss\n",
    "    return total_loss\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "transfer_model.compile(optimizer=opt, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ## 加载图片\n",
    "    X_data = np.load('train/train2014_5000.preprocessing.npy')\n",
    "    X_data = X_data[0:1000, :, :, :]\n",
    "    Y_data = X_data.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # begin training\n",
    "transfer_model.fit(X_data, Y_data, batch_size=2, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "sample_img_path= 'content/0.jpg'\n",
    "sample_size = 256\n",
    "# , target_size=(sample_size, sample_size)\n",
    "img = image.load_img(sample_img_path , target_size=(sample_size, sample_size))\n",
    "x = image.img_to_array(img)\n",
    "plt.imshow(x.astype(int))\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = transfer_model.predict(x)\n",
    "plt.axis('off')\n",
    "plt.imshow(result[0].astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tf2-gpu': conda)",
   "language": "python",
   "name": "python37764bittf2gpucondace5cdca58a4447c2a3d83a62d4d83778"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}